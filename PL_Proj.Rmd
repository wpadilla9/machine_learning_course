---
title: "Qualitative Activity Recognition"
author: "Wesley Padilla"
date: "1/24/2021"
output: pdf_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## Synopsis  

The Qualitative Activity Recognition of Weight Lifting Exercises study (available at http://groupware.les.inf.puc-rio.br/public/papers/2013.Velloso.QAR-WLE.pdf) investigates three aspects that pertain to qualitative activity recognition - specifying correct execution, detecting execution mistakes, and providing feedback to the user. People regularly quantify how much of a particular activity they do but they rarely quantify how well they do it.  In this project we will use data from accelerometers on the belt, forearm, arm, and dumbell of 6 participants who were asked to perform barbell lifts correctly and incorrectly in 5 different ways.  Our objective is to develop a machine learning model to predict the manner in which they did the exercise.  

The "classe" variable in the training set is what we will predict.  Participants were asked to perform one set of 10 repetitions of the Unilateral Dumbbell Biceps Curl in five different fashions: exactly according to the specification (Class A), throwing the elbows to the front (Class B), lifting the dumbbell only halfway (Class C), lowering the dumbbell only halfway (Class D) and throwing the hips to the front (Class E). Class A corresponds to the specified execution of the exercise, while the other 4 classes correspond to common mistakes.  

## Data Sources

The training data for this project are available here:   
https://d396qusza40orc.cloudfront.net/predmachlearn/pml-training.csv   

The test data are available here:  
https://d396qusza40orc.cloudfront.net/predmachlearn/pml-testing.csv    

The data for this project come from this source:   http://web.archive.org/web/20161224072740/http:/groupware.les.inf.puc-rio.br/har   

## Data Processing   

```{r,echo = FALSE}
# Load libraries
library(caret)
library(randomForest)
library(ggplot2)
library(corrplot)
```

```{r,echo = TRUE}
# Load Data
trainURL <- "https://d396qusza40orc.cloudfront.net/predmachlearn/pml-training.csv"
testURL <- "https://d396qusza40orc.cloudfront.net/predmachlearn/pml-testing.csv"
train_in <- read.csv(trainURL, header = T, na.strings = c("", "NA"))
validation_in <- read.csv(testURL, header = T, na.strings = c("", "NA")) 
dim(train_in)
dim(validation_in)
```

R output confirms there are 19,622 observations and 160 variables in the training dataset. The test set includes 20 observations and 60 variables.   

Next step is to remove variables missing values.  

```{r,echo = TRUE}
set.seed(32323)
train_in <- train_in[, colSums(is.na(train_in)) == 0]
validation_in <- validation_in[, colSums(is.na(validation_in)) == 0]
dim(train_in)
dim(validation_in)
```

Removing variables containing missing values reduced the variable count from 160 to 60 in the training set. There were not any changes for the test set.  

## Partitioning the Training Dataset   

Next step is to do data slicing to build training and testing sets.  In the caret package in R, we use the createDataPartition command to perform this function. I sliced the training set so that 70% is allocated to training and 30% is allocated to testing. The inTrain variable gets assigned an indicator function that then subsets out the training set and testing set into variables train_in and validation_in, respectively.      

```{r,echo = TRUE}
inTrain <- createDataPartition(train_in$classe, p=0.7, list=FALSE)
train_in <- train_in[inTrain, ]
validation_in <- validation_in[-inTrain, ]
dim(train_in)
dim(validation_in)
```

Remove variables with near-zero variance.   
```{r,echo = TRUE}
# Remove variables near-zero variance
NZV <- nearZeroVar(train_in)
train_in <- train_in[, -NZV]
validation_in <- validation_in[, -NZV]
dim(train_in)
```
Using the nearZeroVar function reduced variables to 59. Now time to look for highly correlated variables to remove.   


## Explore the Data

```{r,echo = TRUE}
# Use str function to see variable type. Integers will need to change to numeric.  
str(train_in)
```

Several variables will not be required if we are trying to predict the exercise class based on accelerometer 
```{r,echo = TRUE}
# Remove variables not required from the datasets  
train_in <- train_in[, -c(1:6)]
validation_in <- validation_in[, -c(1:6)]
dim(train_in)
dim(validation_in)
```


```{r,echo = TRUE}
# Check correlation and cutoff those variables close to 1
train_in[sapply(train_in, is.numeric)] <- lapply(train_in[sapply(train_in, is.numeric)], as.factor)
```




```{r,echo = TRUE}
fitall <- lm(classe ~ , [, -47])
summary(fitall)
```










